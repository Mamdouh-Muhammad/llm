{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4417f4-9511-4c43-83ca-49a991586530",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to see localhost:6333 locally, you must use codespace in vscode... by opening the codespace in browser, then f1, then Codespaces: Open in VS Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e344edc-1603-4f94-8c18-66d704ad4f6b",
   "metadata": {},
   "source": [
    "# Json + Hybrid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d671ec9d-5198-4a9f-9bb2-49cc57327541",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openai python-dotenv tqdm requests beautifulsoup4\n",
    "#!pip install --upgrade pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3d4400-af5c-4d33-b74a-fbf033a7d894",
   "metadata": {},
   "source": [
    "# Step 1: Connect to Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66ea234-13d6-4042-a640-7d8726199d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from tqdm import tqdm  # Progress bars (e.g., looping through files)\n",
    "from qdrant_client import QdrantClient, models\n",
    "client = QdrantClient(\"http://localhost:6333\") #connecting to local Qdrant instance\n",
    "client.get_collections()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae06713f-cd47-4c5a-982e-02ef53059e22",
   "metadata": {},
   "source": [
    "# Step 2: Sparse vector search with BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850417f5-819f-4a13-9c94-65299bc68de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_url = 'https://raw.githubusercontent.com/Mamdouh-Muhammad/llm/refs/heads/main/rk.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd194d1a-b85d-4fe9-ada5-b168535a6069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for course in documents_raw:\n",
    "#         for doc in course['documents']:\n",
    "#             print(type(doc[\"text\"]), doc[\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56beda7-7f70-4a30-9df7-711dcf7873e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import models\n",
    "\n",
    "# Create the collection with specified sparse vector parameters\n",
    "client.create_collection(\n",
    "    collection_name=\"llm2-sparse\",\n",
    "    sparse_vectors_config={\n",
    "        \"bm25\": models.SparseVectorParams(\n",
    "            modifier=models.Modifier.IDF,\n",
    "        )\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fc19d5-24b2-49c7-a010-322fcdbb9f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "points = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    for doc in course[\"documents\"]:\n",
    "        text = doc[\"text\"]\n",
    "        if isinstance(text, str):\n",
    "            text_str = text\n",
    "        elif isinstance(text, list):\n",
    "            text_str = \" \".join(text)\n",
    "        else:\n",
    "            raise TypeError(f\"Unexpected type for text: {type(text)}\")\n",
    "\n",
    "        point = models.PointStruct(\n",
    "            id=uuid.uuid4().hex,\n",
    "            vector={\n",
    "                \"bm25\": models.Document(\n",
    "                    text=text_str,\n",
    "                    model=\"Qdrant/bm25\"\n",
    "                )\n",
    "            },\n",
    "            payload={\n",
    "                \"text\": text,\n",
    "                \"section\": doc[\"section\"],\n",
    "                \"course\": course[\"course\"]\n",
    "            }\n",
    "        )\n",
    "        points.append(point)\n",
    "\n",
    "# âœ… Now send the points\n",
    "client.upsert(\n",
    "    collection_name=\"llm2-sparse\",\n",
    "    points=points\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f9405f-ed5f-4e83-82aa-5e4e9edee2fa",
   "metadata": {},
   "source": [
    "# Step 3: Running sparse vector search with BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ca2504-b51b-432f-bcd0-6d29fd07db3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query: str, limit: int = 1) -> list[models.ScoredPoint]:\n",
    "    results = client.query_points(\n",
    "        collection_name=\"llm2-sparse\",\n",
    "        query=models.Document(\n",
    "            text=query,\n",
    "            model=\"Qdrant/bm25\",\n",
    "        ),\n",
    "        using=\"bm25\",\n",
    "        limit=limit,\n",
    "        with_payload=True,\n",
    "    )\n",
    "\n",
    "    return results.points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97735c45-54c6-4542-96c5-5e843fd6a999",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = search(\"Tutor\")\n",
    "print(results[0].payload[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a034ac7-a76f-4f65-8fca-d4cbdbb1e3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0].score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a544b89a-aa5f-4c8a-84db-4c2816871ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "\n",
    "random.seed(22)\n",
    "\n",
    "course = random.choice(documents_raw)\n",
    "course_piece = random.choice(course[\"documents\"])\n",
    "print(json.dumps(course_piece, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d41505e-24d9-486b-b744-e896559fd3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = search(course_piece[\"question\"])\n",
    "print(results[0].payload[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3799f89a-1491-4e25-a9c2-41af7734a08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the collection with both vector types\n",
    "client.create_collection(\n",
    "    collection_name=\"llm-sparse-and-dense\",\n",
    "    vectors_config={\n",
    "        # Named dense vector for jinaai/jina-embeddings-v2-small-en\n",
    "        \"jina-small\": models.VectorParams(\n",
    "            size=512,\n",
    "            distance=models.Distance.COSINE,\n",
    "        ),\n",
    "    },\n",
    "    sparse_vectors_config={\n",
    "        \"bm25\": models.SparseVectorParams(\n",
    "            modifier=models.Modifier.IDF,\n",
    "        )\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c539d2-5a15-4b11-9357-32c25d687496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from qdrant_client import QdrantClient, models\n",
    "\n",
    "client.upsert(\n",
    "    collection_name=\"llm-sparse-and-dense\",\n",
    "    points=[\n",
    "        models.PointStruct(\n",
    "            id=uuid.uuid4().hex,\n",
    "            vector={\n",
    "                \"jina-small\": models.Document(\n",
    "                    text=(\n",
    "                        doc[\"text\"]\n",
    "                        if isinstance(doc[\"text\"], str)\n",
    "                        else \" \".join(doc[\"text\"])\n",
    "                    ),\n",
    "                    model=\"jinaai/jina-embeddings-v2-small-en\",\n",
    "                ),\n",
    "                \"bm25\": models.Document(\n",
    "                    text=(\n",
    "                        doc[\"text\"]\n",
    "                        if isinstance(doc[\"text\"], str)\n",
    "                        else \" \".join(doc[\"text\"])\n",
    "                    ),\n",
    "                    model=\"Qdrant/bm25\",\n",
    "                ),\n",
    "            },\n",
    "            payload={\n",
    "                \"text\": doc[\"text\"],\n",
    "                \"section\": doc[\"section\"],\n",
    "                \"course\": course[\"course\"],\n",
    "            }\n",
    "        )\n",
    "        for course in documents_raw\n",
    "        for doc in course[\"documents\"]\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bc1f33-2ea4-43a9-98f1-f45302dc11cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_stage_search(query: str, limit: int = 1) -> list[models.ScoredPoint]:\n",
    "    results = client.query_points(\n",
    "        collection_name=\"llm-sparse-and-dense\",\n",
    "        prefetch=[\n",
    "            models.Prefetch(\n",
    "                query=models.Document(\n",
    "                    text=query,\n",
    "                    model=\"jinaai/jina-embeddings-v2-small-en\",\n",
    "                ),\n",
    "                using=\"jina-small\",\n",
    "                # Prefetch ten times more results, then\n",
    "                # expected to return, so we can really rerank\n",
    "                limit=(10 * limit),\n",
    "            ),\n",
    "        ],\n",
    "        query=models.Document(\n",
    "            text=query,\n",
    "            model=\"Qdrant/bm25\", \n",
    "        ),\n",
    "        using=\"bm25\",\n",
    "        limit=limit,\n",
    "        with_payload=True,\n",
    "    )\n",
    "\n",
    "    return results.points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001da21b-04b1-436b-9392-0b3a7db55ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(course_piece, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82833bda-d12d-4186-8e4b-7d4d0201911b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = multi_stage_search(course_piece[\"question\"])\n",
    "print(results[0].payload[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044bc7dd-961b-423f-a040-b076415809a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rrf_search(query: str, limit: int = 1) -> list[models.ScoredPoint]:\n",
    "    results = client.query_points(\n",
    "        collection_name=\"llm-sparse-and-dense\",\n",
    "        prefetch=[\n",
    "            models.Prefetch(\n",
    "                query=models.Document(\n",
    "                    text=query,\n",
    "                    model=\"jinaai/jina-embeddings-v2-small-en\",\n",
    "                ),\n",
    "                using=\"jina-small\",\n",
    "                limit=(5 * limit),\n",
    "            ),\n",
    "            models.Prefetch(\n",
    "                query=models.Document(\n",
    "                    text=query,\n",
    "                    model=\"Qdrant/bm25\",\n",
    "                ),\n",
    "                using=\"bm25\",\n",
    "                limit=(5 * limit),\n",
    "            ),\n",
    "        ],\n",
    "        # Fusion query enables fusion on the prefetched results\n",
    "        query=models.FusionQuery(fusion=models.Fusion.RRF),\n",
    "        with_payload=True,\n",
    "    )\n",
    "\n",
    "    return results.points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce524f5-2a18-432b-bc52-5f05b6ab89f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = rrf_search(course_piece[\"question\"])\n",
    "print(json.dumps(course_piece, indent=2))\n",
    "print(results[0].payload[\"text\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
